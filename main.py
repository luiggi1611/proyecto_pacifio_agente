import streamlit as st
import os
import openai
import base64
import io
from PIL import Image
from datetime import datetime
import tempfile
import traceback
import uuid  # <-- FALTABA ESTE

# Importar m√≥dulos personalizados
from models import GraphState, ConversationStep, BusinessInfo, SerializableImage
from insurance_graph import InsuranceAgentGraph,LLMControlledInsuranceAgent
from certificate_analyzer import extract_text_from_document


import streamlit as st
import os
import openai
import base64
import io
import uuid  # <-- FALTABA ESTE
from PIL import Image
from datetime import datetime
import tempfile
import traceback

# Importar m√≥dulos personalizados
from models import GraphState, ConversationStep, BusinessInfo, SerializableImage
from certificate_analyzer import extract_text_from_document

# NUEVO: Import del agente LLM
from llm_controlled_agent import LLMControlledInsuranceAgent  # <-- AGREGAR ESTE

# Resto de imports existentes...

def setup_insurance_agent(api_key: str):
    """Configura el agente de seguros controlado por LLM - CORREGIDO"""
    try:
        if not st.session_state.get("insurance_agent"):
            st.session_state.insurance_agent = LLMControlledInsuranceAgent(api_key)
            st.session_state.graph_state = create_initial_state()
            
            # Mensaje de bienvenida inicial
            welcome_message = {
                "role": "assistant",
                "content": """¬°Hola! Soy tu agente de seguros comerciales de Seguros Pac√≠fico.

Estoy aqu√≠ para ayudarte a crear una p√≥liza personalizada para tu negocio de manera completamente conversacional. 

Puedes:
üìÑ Subir tu certificado de funcionamiento
üì∏ Enviar fotos de tu local
üí¨ Contarme sobre tu negocio directamente

Solo comparte la informaci√≥n que tengas disponible y yo me encargar√© de guiarte naturalmente en el proceso. ¬øC√≥mo te gustar√≠a empezar?"""
            }
            
            st.session_state.graph_state["messages"] = [welcome_message]
            
        return True
    except Exception as e:
        st.error(f"Error configurando el agente: {str(e)}")
        import traceback
        traceback.print_exc()  # Para ver el error completo
        return False

def create_initial_state() -> dict:  # Cambiado de GraphState a dict
    """Crea el estado inicial simplificado"""
    return {
        "messages": [],
        "business_info": BusinessInfo(),
        "valuation": None,
        "certificate_text": None,
        "certificate_images": [],
        "local_photos": [],
        "policy": None,
        "audio_file": None,
        "audio_summary": None,
        "session_id": str(uuid.uuid4()),
        "timestamp": datetime.now().isoformat()
    }

# Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="ü§ñ Agente de Seguros IA - Pac√≠fico",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
.main-header {
    background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
    padding: 1rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
}

.progress-item {
    padding: 0.5rem;
    margin: 0.2rem 0;
    border-radius: 5px;
    border-left: 4px solid #2a5298;
}

.completed {
    background-color: #d4edda;
    border-left-color: #28a745;
}

.pending {
    background-color: #f8f9fa;
    border-left-color: #6c757d;
}

.chat-container {
    max-height: 600px;
    overflow-y: auto;
    padding: 1rem;
    border: 1px solid #ddd;
    border-radius: 10px;
    background-color: #fafafa;
}
</style>
""", unsafe_allow_html=True)

def debug_log(message, data=None):
    """Funci√≥n para logging de debug"""
    print(f"[DEBUG] {message}")
    if data:
        print(f"[DEBUG DATA] {data}")
    
    # Tambi√©n mostrar en Streamlit si est√° en debug mode
    if st.session_state.get("debug_mode", False):
        st.write(f"üîç DEBUG: {message}")
        if data:
            st.json(data)

def classify_image_type(image: Image.Image, api_key: str) -> str:
    """Clasifica si una imagen es un certificado o foto del local usando GPT-4 Vision"""
    try:
        debug_log("Iniciando clasificaci√≥n de imagen")
        client = openai.OpenAI(api_key=api_key)
        
        # Convertir imagen a base64
        buffer = io.BytesIO()
        # Redimensionar para reducir tokens
        if image.width > 800:
            ratio = 800 / image.width
            new_height = int(image.height * ratio)
            image = image.resize((800, new_height), Image.Resampling.LANCZOS)
        
        image.save(buffer, format='JPEG', quality=85)
        img_str = base64.b64encode(buffer.getvalue()).decode()
        
        debug_log(f"Imagen redimensionada a {image.size}, tama√±o base64: {len(img_str)} chars")
        
        prompt = """
Analiza esta imagen y determina si es:
1. Un CERTIFICADO DE FUNCIONAMIENTO (documento oficial con texto, sellos, firmas)
2. Una FOTO DEL LOCAL COMERCIAL (interior, exterior, inventario, mobiliario)

Responde SOLO con una palabra:
- "certificate" si es un certificado de funcionamiento
- "local_photo" si es una foto del local/negocio
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{img_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=10,
            temperature=0
        )
        
        result = response.choices[0].message.content.strip().lower()
        classification = "certificate" if "certificate" in result else "local_photo"
        debug_log(f"Clasificaci√≥n de imagen: {classification} (respuesta: {result})")
        return classification
        
    except Exception as e:
        debug_log(f"Error clasificando imagen: {str(e)}")
        traceback.print_exc()
        return "local_photo"
def process_uploaded_image(uploaded_file, graph_state, insurance_graph, api_key):
    """Procesa una imagen subida, la clasifica y actualiza el estado - CORREGIDO"""
    try:
        debug_log(f"Procesando imagen: {uploaded_file.name}")
        
        # Convertir a PIL Image
        pil_image = Image.open(uploaded_file)
        debug_log(f"PIL Image cargada: {pil_image.size}, modo: {pil_image.mode}")
        
        # Clasificar tipo de imagen
        image_type = classify_image_type(pil_image, api_key)
        debug_log(f"Tipo de imagen detectado: {image_type}")
        
        if image_type == "certificate":
            # Procesamiento de certificado (sin cambios)
            debug_log("Procesando como certificado...")
            try:
                business_info_extracted = insurance_graph.nodes.certificate_analyzer.analyze_image(pil_image)
                debug_log("Datos extra√≠dos del certificado:", business_info_extracted.to_dict())
                
                serializable_image = SerializableImage.from_pil_image(pil_image, "certificado_funcionamiento.jpg")
                graph_state["certificate_images"] = [serializable_image]
                
                existing_info = graph_state["business_info"]
                for field, value in business_info_extracted.to_dict().items():
                    if value and not getattr(existing_info, field, None):
                        setattr(existing_info, field, value)
                
                # Generar mensaje de respuesta para certificado
                summary_parts = []
                if existing_info.nombre_cliente:
                    summary_parts.append(f"Cliente: {existing_info.nombre_cliente}")
                if existing_info.direccion:
                    summary_parts.append(f"Direcci√≥n: {existing_info.direccion}")
                if existing_info.tipo_negocio:
                    summary_parts.append(f"Tipo: {existing_info.tipo_negocio}")
                if existing_info.metraje:
                    summary_parts.append(f"√Årea: {existing_info.metraje}m¬≤")
                if existing_info.ruc:
                    summary_parts.append(f"RUC: {existing_info.ruc}")
                
                if summary_parts:
                    response_msg = f"üìÑ He analizado tu certificado de funcionamiento:\n\n" + "\n".join([f"‚Ä¢ {part}" for part in summary_parts])
                    
                    if not existing_info.metraje:
                        response_msg += "\n\n‚ùì No encontr√© el metraje en el certificado. ¬øPodr√≠as decirme cu√°ntos metros cuadrados tiene tu local?"
                    else:
                        response_msg += "\n\nüì∏ Siguiente paso: Necesito fotos del local para hacer la valuaci√≥n precisa."
                else:
                    response_msg = "üìÑ He procesado el certificado pero no pude extraer informaci√≥n clara. ¬øPodr√≠as proporcionarme los datos manualmente?"
                
                new_state = graph_state
                debug_log("Certificado procesado exitosamente")
                
            except Exception as e:
                debug_log(f"Error procesando certificado: {str(e)}")
                new_state = graph_state
                response_msg = f"Error procesando certificado: {str(e)}"
            
        else:  # local_photo
            debug_log("Procesando como foto del local...")
            try:
                # Crear SerializableImage
                filename = uploaded_file.name or f"local_foto.jpg"
                serializable_image = SerializableImage.from_pil_image(pil_image, filename)
                
                # Agregar a fotos del local
                current_photos = graph_state.get("local_photos", [])
                current_photos.append(serializable_image)
                graph_state["local_photos"] = current_photos
                debug_log(f"Foto agregada. Total fotos: {len(current_photos)}")
                
                # AQU√ç EST√Å EL PROBLEMA - No ejecutar el grafo autom√°ticamente
                # Solo agregar mensaje de confirmaci√≥n
                
                if graph_state["business_info"].metraje:
                    response_msg = f"""üì∑ Perfecto, he recibido una foto de tu local comercial. 
                    
Ahora tengo {len(current_photos)} imagen(es) del negocio y toda la informaci√≥n necesaria:
‚Ä¢ {graph_state["business_info"].tipo_negocio or 'Negocio comercial'}
‚Ä¢ {graph_state["business_info"].metraje}m¬≤
‚Ä¢ {len(current_photos)} foto(s) del local

¬øQuieres que proceda a calcular la valuaci√≥n de tu seguro?"""
                    
                    # NO ejecutar el grafo autom√°ticamente
                    # Establecer el estado para que est√© listo pero esperando confirmaci√≥n
                    graph_state["next_action"] = "ready_for_valuation"
                    graph_state["ready_for_policy"] = False
                    new_state = graph_state
                    
                else:
                    response_msg = f"üì∑ He recibido una foto de tu local. Total: {len(current_photos)} imagen(es).\n\nPara calcular la valuaci√≥n, a√∫n necesito que me confirmes el metraje de tu local."
                    graph_state["next_action"] = "request_metraje"
                    new_state = graph_state
                
                debug_log("Foto del local procesada exitosamente")
                
            except Exception as e:
                debug_log(f"Error procesando foto del local: {str(e)}")
                new_state = graph_state
                response_msg = f"Error procesando foto: {str(e)}"
        
        return new_state, response_msg
        
    except Exception as e:
        error_msg = f"Error general procesando imagen: {str(e)}"
        debug_log(error_msg)
        return graph_state, error_msg
def initialize_session_state():
    """Inicializa el estado de la sesi√≥n"""
    if "api_key" not in st.session_state:
        st.session_state.api_key = ""
    
    if "insurance_graph" not in st.session_state:
        st.session_state.insurance_graph = None
    
    if "graph_state" not in st.session_state:
        st.session_state.graph_state = None
    
    if "conversation_initialized" not in st.session_state:
        st.session_state.conversation_initialized = False

def setup_insurance_graph(api_key: str):
    """Configura el grafo de seguros"""
    try:
        if not st.session_state.insurance_graph:
            st.session_state.insurance_graph = InsuranceAgentGraph(api_key)
            st.session_state.graph_state = st.session_state.insurance_graph.create_initial_state()
            
            # Ejecutar nodo de bienvenida
            config = {"configurable": {"thread_id": st.session_state.graph_state["session_id"]}}
            st.session_state.graph_state = st.session_state.insurance_graph.graph.invoke(
                st.session_state.graph_state, config
            )
            st.session_state.conversation_initialized = True
            
        return True
    except Exception as e:
        st.error(f"Error configurando el agente: {str(e)}")
        return False

def render_progress_panel():
    """Renderiza el panel de progreso"""
    st.subheader("üìä Progreso del Seguro")
    
    if not st.session_state.graph_state:
        return
    
    state = st.session_state.graph_state
    business_info = state.get("business_info", BusinessInfo())
    
    progress_items = [
        ("üìÑ Certificado", bool(business_info.direccion or business_info.tipo_negocio)),
        ("üìè Metraje", bool(business_info.metraje)),
        ("üì∏ Fotos Local", len(state.get("local_photos", [])) > 0),
        ("üí∞ Valuaci√≥n", bool(state.get("valuation"))),
        ("üìã P√≥liza", bool(state.get("policy"))),
        ("üîä Audio", bool(state.get("audio_file")))
    ]
    
    for item, completed in progress_items:
        if completed:
            st.markdown(f"""
            <div class="progress-item completed">
                ‚úÖ {item}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="progress-item pending">
                ‚è≥ {item}
            </div>
            """, unsafe_allow_html=True)

def render_business_info_panel():
    """Renderiza el panel de informaci√≥n del negocio"""
    if not st.session_state.graph_state:
        return
    
    business_info = st.session_state.graph_state.get("business_info", BusinessInfo())
    valuation = st.session_state.graph_state.get("valuation")
    
    if any([business_info.tipo_negocio, business_info.metraje, business_info.direccion]):
        st.subheader("üè¢ Informaci√≥n del Negocio")
        
        if business_info.nombre_cliente:
            st.write(f"**Cliente:** {business_info.nombre_cliente}")
        if business_info.tipo_negocio:
            st.write(f"**Tipo:** {business_info.tipo_negocio}")
        if business_info.metraje:
            st.write(f"**√Årea:** {business_info.metraje} m¬≤")
        if business_info.direccion:
            st.write(f"**Direcci√≥n:** {business_info.direccion}")
        if business_info.ruc:
            st.write(f"**RUC:** {business_info.ruc}")
        
        if valuation:
            st.write(f"**Valor estimado:** S/ {valuation.total:,.2f}")

def render_downloads_panel():
    """Renderiza el panel de descargas - CORREGIDO"""
    if not st.session_state.graph_state:
        return
    
    state = st.session_state.graph_state
    
    if state.get("policy") or state.get("audio_file"):
        st.subheader("üì• Descargar Documentos")
        
        # Descargar p√≥liza
        if state.get("policy"):
            policy_content = state["policy"].content
            st.download_button(
                "üìÑ Descargar P√≥liza",
                data=policy_content,
                file_name=f"poliza_seguro_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                mime="text/plain",
                use_container_width=True
            )
            st.success("‚úÖ P√≥liza lista para descargar")
        
        # Descargar y reproducir audio
        if state.get("audio_file"):
            audio_file_path = state["audio_file"]
            print(f"[DEBUG] Intentando cargar audio desde: {audio_file_path}")
            
            try:
                import os
                if os.path.exists(audio_file_path):
                    with open(audio_file_path, 'rb') as audio_file:
                        audio_data = audio_file.read()
                        
                    # Bot√≥n de descarga
                    st.download_button(
                        "üîä Descargar Audio",
                        data=audio_data,
                        file_name=f"resumen_poliza_{datetime.now().strftime('%Y%m%d_%H%M')}.mp3",
                        mime="audio/mp3",
                        use_container_width=True
                    )
                    
                    # Reproductor de audio
                    st.audio(audio_data, format='audio/mp3')
                    st.success("‚úÖ Audio listo para descargar y reproducir")
                    
                    # Mostrar resumen del audio si est√° disponible
                    if state.get("audio_summary"):
                        with st.expander("üìù Transcript del audio"):
                            st.write(state["audio_summary"])
                else:
                    st.error(f"‚ùå Archivo de audio no encontrado: {audio_file_path}")
                    print(f"[DEBUG] Archivo no existe: {audio_file_path}")
                    # Limpiar referencia de audio inv√°lida
                    st.session_state.graph_state["audio_file"] = None
                    
            except Exception as e:
                st.error(f"‚ùå Error cargando audio: {str(e)}")
                print(f"[DEBUG] Error cargando audio: {str(e)}")
                import traceback
                traceback.print_exc()
        
        # Debug info si est√° habilitado
        if st.session_state.get("debug_mode", False):
            st.subheader("üîç Debug - Estado de Archivos")
            st.write(f"**Tiene p√≥liza:** {bool(state.get('policy'))}")
            st.write(f"**Ruta de audio:** {state.get('audio_file', 'None')}")
            st.write(f"**Audio summary:** {bool(state.get('audio_summary'))}")
            
            if state.get("audio_file"):
                import os
                audio_exists = os.path.exists(state["audio_file"])
                st.write(f"**Archivo de audio existe:** {audio_exists}")
                if audio_exists:
                    audio_size = os.path.getsize(state["audio_file"])
                    st.write(f"**Tama√±o del archivo:** {audio_size} bytes")
def debug_audio_generation():
    """Debug espec√≠fico para generaci√≥n de audio"""
    if st.session_state.get("graph_state") and st.session_state.get("insurance_agent"):
        st.subheader("üîä Debug - Generaci√≥n de Audio")
        
        state = st.session_state.graph_state
        
        # Verificar prerequisitos
        has_policy = bool(state.get("policy"))
        has_business_info = bool(state.get("business_info"))
        has_valuation = bool(state.get("valuation"))
        
        st.write(f"**Tiene p√≥liza:** {has_policy}")
        st.write(f"**Tiene business_info:** {has_business_info}")
        st.write(f"**Tiene valuaci√≥n:** {has_valuation}")
        
        if has_policy and has_business_info and has_valuation:
            if st.button("üß™ Test Generaci√≥n Manual de Audio"):
                with st.spinner("Generando audio manualmente..."):
                    try:
                        policy_gen = st.session_state.insurance_agent.policy_generator
                        audio_file, summary_text = policy_gen.generate_audio_summary(
                            state["business_info"],
                            state["valuation"],
                            state["policy"]
                        )
                        
                        if audio_file:
                            # Actualizar estado
                            st.session_state.graph_state["audio_file"] = audio_file
                            st.session_state.graph_state["audio_summary"] = summary_text
                            
                            st.success(f"‚úÖ Audio generado: {audio_file}")
                            st.rerun()
                        else:
                            st.error("‚ùå No se pudo generar el audio")
                            
                    except Exception as e:
                        st.error(f"‚ùå Error en test: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
        else:
            st.warning("‚ö†Ô∏è Faltan prerequisitos para generar audio")


def check_and_update_audio_state():
    """Verifica y actualiza el estado del audio despu√©s de que el LLM lo genere"""
    
    if not st.session_state.get("graph_state"):
        return
    
    state = st.session_state.graph_state
    
    # Si se menciona audio en el √∫ltimo mensaje del asistente, verificar estado
    messages = state.get("messages", [])
    if messages:
        last_message = messages[-1]
        if (last_message.get("role") == "assistant" and 
            ("audio" in last_message.get("content", "").lower() or 
             "resumen" in last_message.get("content", "").lower())):
            
            # Verificar si realmente se gener√≥ el audio
            audio_file = state.get("audio_file")
            if audio_file:
                import os
                if not os.path.exists(audio_file):
                    print(f"[DEBUG] Audio mencionado pero archivo no existe: {audio_file}")
                    # Limpiar referencia inv√°lida
                    st.session_state.graph_state["audio_file"] = None
                    st.session_state.graph_state["audio_summary"] = None
                else:
                    print(f"[DEBUG] Audio confirmado: {audio_file}")
def render_image_gallery():
    """Renderiza galer√≠a de im√°genes subidas"""
    if not st.session_state.graph_state:
        return
    
    state = st.session_state.graph_state
    local_photos = state.get("local_photos", [])
    
    if local_photos:
        st.subheader("üñºÔ∏è Fotos del Local")
        
        # Mostrar fotos en filas de 3
        cols_per_row = 3
        for i in range(0, len(local_photos), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                if i + j < len(local_photos):
                    with col:
                        try:
                            photo = local_photos[i + j]
                            pil_image = photo.to_pil_image()
                            st.image(pil_image, caption=f"Foto {i+j+1}", use_column_width=True)
                        except Exception as e:
                            st.error(f"Error mostrando imagen {i+j+1}: {str(e)}")
    
    # Tambi√©n mostrar certificados si los hay
    certificate_images = state.get("certificate_images", [])
    if certificate_images:
        st.subheader("üìÑ Certificado de Funcionamiento")
        
        for i, cert_image in enumerate(certificate_images):
            try:
                pil_image = cert_image.to_pil_image()
                st.image(pil_image, caption=f"Certificado {i+1}", use_column_width=True)
            except Exception as e:
                st.error(f"Error mostrando certificado {i+1}: {str(e)}")
    
    # Verificar si st.chat_input est√° disponible con file_uploader
    try:
        # Input del usuario con soporte para archivos
        user_input = st.chat_input(
            "Escribe tu mensaje o sube una imagen (certificado o foto del local)...",
            accept_file=True,
            file_type=["jpg", "jpeg", "png"]
        )
        debug_log("st.chat_input con file_uploader disponible")
    except Exception as e:
        debug_log(f"Error con st.chat_input file_uploader: {str(e)}")
        st.error("Tu versi√≥n de Streamlit no soporta file_uploader en chat_input. Actualiza a la versi√≥n m√°s reciente.")
        
        # Fallback: usar input normal y file_uploader separado
        col1, col2 = st.columns([3, 1])
        with col1:
            user_text = st.chat_input("Escribe tu mensaje...")
        with col2:
            uploaded_file = st.file_uploader("Subir imagen", type=["jpg", "jpeg", "png"], key="fallback_upload")
        
        # Simular estructura de user_input
        user_input = {}
        if user_text:
            user_input["message"] = user_text
        if uploaded_file:
            user_input["file"] = uploaded_file
        
        if not user_text and not uploaded_file:
            user_input = None
    
    if user_input:
        debug_log("Input del usuario recibido", user_input.keys() if isinstance(user_input, dict) else type(user_input))
        
        message = user_input.get("message") if isinstance(user_input, dict) else None
        uploaded_files = user_input.get("file") if isinstance(user_input, dict) else None
        
        # Si user_input es string (texto simple)
        if isinstance(user_input, str):
            message = user_input
            uploaded_file = None
        
        # Procesar mensaje de texto
        if message:
            debug_log(f"Procesando mensaje de texto: {message[:50]}...")
            with st.spinner("Procesando mensaje..."):
                try:
                    st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                        st.session_state.graph_state, message
                    )
                    debug_log("Mensaje procesado exitosamente")
                except Exception as e:
                    debug_log(f"Error procesando mensaje: {str(e)}")
                    traceback.print_exc()
                    st.error(f"Error procesando mensaje: {str(e)}")
            st.rerun()  
        
        # Procesar imagen subida
        if uploaded_files:
            for i, uploaded_file in enumerate(uploaded_files):
                debug_log(f"Procesando imagen {i+1}: {uploaded_file.name}")
                
                # NUEVO: Debug del estado ANTES de procesar
                debug_log("Estado del grafo ANTES de procesar imagen:", {
                    "business_info": st.session_state.graph_state["business_info"].to_dict(),
                    "messages_count": len(st.session_state.graph_state["messages"]),
                    "current_step": str(st.session_state.graph_state["current_step"])
                })
                
                # IMPORTANTE: Agregar imagen del usuario al historial ANTES de procesar
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": f"üìé Imagen subida: {uploaded_file.name}"
                })
                
                with st.spinner(f"Analizando imagen {i+1} autom√°ticamente..."):
                    try:
                        # Procesar la imagen autom√°ticamente
                        new_state, response_msg = process_uploaded_image(
                            uploaded_file, 
                            st.session_state.graph_state,
                            st.session_state.insurance_graph,
                            st.session_state.api_key
                        )
                        
                        # NUEVO: Debug del estado DESPU√âS de procesar
                        debug_log("Estado del grafo DESPU√âS de procesar imagen:", {
                            "business_info": new_state["business_info"].to_dict(),
                            "messages_count": len(new_state["messages"]),
                            "current_step": str(new_state["current_step"]),
                            "certificate_images": len(new_state.get("certificate_images", [])),
                            "local_photos": len(new_state.get("local_photos", []))
                        })
                        
                        # Actualizar estado
                        st.session_state.graph_state = new_state
                        
                        # IMPORTANTE: Agregar respuesta del asistente al historial
                        st.session_state.graph_state["messages"].append({
                            "role": "assistant",
                            "content": response_msg
                        })
                        
                        # NUEVO: Debug final del estado
                        debug_log("Estado FINAL despu√©s de agregar mensajes:", {
                            "business_info_final": st.session_state.graph_state["business_info"].to_dict(),
                            "messages_count_final": len(st.session_state.graph_state["messages"])
                        })
                            
                        debug_log(f"Imagen {i+1} procesada exitosamente")
                        
                    except Exception as e:
                        debug_log(f"Error procesando imagen {i+1}: {str(e)}")
                        traceback.print_exc()
                        # Agregar mensaje de error al historial
                        st.session_state.graph_state["messages"].append({
                            "role": "assistant",
                            "content": f"Error procesando imagen {uploaded_file.name}: {str(e)}"
                        })
            
            st.rerun()

def test_openai_connection(api_key):
    """Prueba la conexi√≥n con OpenAI"""
    try:
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Test"}],
            max_tokens=5
        )
        return True, "Conexi√≥n exitosa"
    except Exception as e:
        return False, str(e)

def debug_setup():
    """Setup inicial de debugging"""
    st.sidebar.subheader("üîß Debug Info")
    
    # Test de API Key
    if st.session_state.get("api_key"):
        if st.sidebar.button("Test API Key"):
            success, message = test_openai_connection(st.session_state.api_key)
            if success:
                st.sidebar.success("‚úÖ API Key funciona")
            else:
                st.sidebar.error(f"‚ùå Error API Key: {message}")
    
    # Informaci√≥n de Streamlit
    st.sidebar.text(f"Streamlit: {st.__version__}")
    
    # Estado del grafo
    if st.session_state.get("graph_state"):
        st.sidebar.text(f"Session ID: {st.session_state.graph_state.get('session_id', 'N/A')[:8]}...")
        st.sidebar.text(f"Messages: {len(st.session_state.graph_state.get('messages', []))}")
    
    # Reiniciar estado completo
    if st.sidebar.button("üóëÔ∏è Reset Completo"):
        st.session_state.clear()
        st.rerun()
def render_conversation():
    """Renderiza la conversaci√≥n con soporte autom√°tico para im√°genes usando st.chat_input - CORREGIDO"""
    st.subheader("üí¨ Conversaci√≥n con tu Agente de Seguros")
    
    # Toggle para modo debug
    st.session_state.debug_mode = st.checkbox("üîç Modo Debug", value=st.session_state.get("debug_mode", False))
    
    if not st.session_state.graph_state:
        st.warning("Configura tu API Key para comenzar")
        return
    
    # Mostrar estado actual en debug mode
    if st.session_state.debug_mode:
        with st.expander("Estado Actual del Grafo", expanded=False):
            st.json({
                "current_step": str(st.session_state.graph_state.get("current_step", "Unknown")),
                "message_count": len(st.session_state.graph_state.get("messages", [])),
                "business_info": st.session_state.graph_state.get("business_info", {}).to_dict() if st.session_state.graph_state.get("business_info") else {},
                "local_photos_count": len(st.session_state.graph_state.get("local_photos", [])),
                "next_action": st.session_state.graph_state.get("next_action", "Unknown")
            })
    
    # Contenedor de chat
    chat_container = st.container()
    
    with chat_container:
        # Mostrar mensajes de la conversaci√≥n
        messages = st.session_state.graph_state.get("messages", [])
        debug_log(f"Mostrando {len(messages)} mensajes")
        
        for i, message in enumerate(messages):
            if message["role"] == "user":
                st.chat_message("user").write(message["content"])
            else:
                st.chat_message("assistant").write(message["content"])
    
    # Chat input con soporte para archivos
    try:
        # Intentar usar st.chat_input con file support
        prompt = st.chat_input(
            "Escribe tu mensaje o sube una imagen (certificado o foto del local)...",
            accept_file=True,
            file_type=["jpg", "jpeg", "png"]
        )
    except Exception as e:
        debug_log(f"Error con st.chat_input file_uploader: {str(e)}")
        # Fallback: usar input normal y file_uploader separado
        col1, col2 = st.columns([4, 1])
        with col1:
            text_input = st.text_input("Escribe tu mensaje:", key="fallback_text")
        with col2:
            uploaded_files = st.file_uploader("Subir imagen", type=["jpg", "jpeg", "png"], 
                                            accept_multiple_files=True, key="fallback_upload")
        
        # Crear estructura similar a prompt
        prompt = None
        if text_input or uploaded_files:
            prompt = {
                'text': text_input if text_input else "",
                'files': uploaded_files if uploaded_files else []
            }
    
    if prompt:
        debug_log("Input del usuario recibido", type(prompt))
        
        # CORREGIDO: Manejar diferentes tipos de input de forma consistente
        if isinstance(prompt, str):
            # Input de solo texto
            user_message = prompt
            uploaded_files = []
            debug_log(f"Mensaje de texto: {user_message[:50]}...")
            
        elif hasattr(prompt, 'text') and hasattr(prompt, 'files'):
            # Streamlit chat_input con archivos
            user_message = prompt.text if prompt.text else ""
            uploaded_files = prompt.files if prompt.files else []
            debug_log(f"Chat input - Mensaje: '{user_message}', Archivos: {len(uploaded_files)}")
            
        elif isinstance(prompt, dict):
            # Fallback dict format
            user_message = prompt.get('text', '')
            uploaded_files = prompt.get('files', [])
            debug_log(f"Dict input - Mensaje: '{user_message}', Archivos: {len(uploaded_files)}")
            
        else:
            debug_log(f"Tipo de prompt no reconocido: {type(prompt)}")
            user_message = str(prompt)
            uploaded_files = []
        
        # Procesar mensaje de texto si existe
        if user_message and user_message.strip():
            debug_log(f"Procesando mensaje de texto: {user_message[:50]}...")
            
            # IMPORTANTE: Agregar mensaje del usuario al historial ANTES de procesar
            st.session_state.graph_state["messages"].append({
                "role": "user",
                "content": user_message
            })
            
            with st.spinner("Procesando mensaje..."):
                try:
                    # NUEVO: Debug antes de process_user_input
                    debug_log("ANTES de process_user_input:", {
                        "user_input_to_process": user_message,
                        "current_step": str(st.session_state.graph_state.get("current_step")),
                        "needs_confirmation": st.session_state.graph_state.get("needs_confirmation"),
                        "has_valuation": bool(st.session_state.graph_state.get("valuation")),
                        "has_policy": bool(st.session_state.graph_state.get("policy"))
                    })
                    
                    # Ejecutar process_user_input
                    st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                        st.session_state.graph_state, user_message
                    )
                    
                    # NUEVO: Debug despu√©s de process_user_input
                    debug_log("DESPU√âS de process_user_input:", {
                        "current_step": str(st.session_state.graph_state.get("current_step")),
                        "needs_confirmation": st.session_state.graph_state.get("needs_confirmation"),
                        "has_policy": bool(st.session_state.graph_state.get("policy")),
                        "next_action": st.session_state.graph_state.get("next_action")
                    })
                    
                    debug_log("Mensaje procesado exitosamente")
                    
                except Exception as e:
                    debug_log(f"ERROR en process_user_input: {str(e)}")
                    # Agregar mensaje de error al historial
                    st.session_state.graph_state["messages"].append({
                        "role": "assistant",
                        "content": f"Disculpa, hubo un error procesando tu mensaje. ¬øPodr√≠as intentar de nuevo? Error: {str(e)}"
                    })
        
        # Procesar archivos subidos si existen
        if uploaded_files:
            # Asegurar que uploaded_files sea una lista
            if not isinstance(uploaded_files, list):
                uploaded_files = [uploaded_files]
                
            for i, uploaded_file in enumerate(uploaded_files):
                debug_log(f"Procesando imagen {i+1}: {uploaded_file.name}")
                
                # IMPORTANTE: Agregar imagen del usuario al historial ANTES de procesar
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": f"üîé Imagen subida: {uploaded_file.name}"
                })
                
                with st.spinner(f"Analizando imagen {i+1} autom√°ticamente..."):
                    try:
                        # Procesar la imagen autom√°ticamente
                        new_state, response_msg = process_uploaded_image(
                            uploaded_file, 
                            st.session_state.graph_state,
                            st.session_state.insurance_graph,
                            st.session_state.api_key
                        )
                        
                        # Actualizar estado
                        st.session_state.graph_state = new_state
                        
                        # IMPORTANTE: Agregar respuesta del asistente al historial
                        st.session_state.graph_state["messages"].append({
                            "role": "assistant",
                            "content": response_msg
                        })
                            
                        debug_log(f"Imagen {i+1} procesada exitosamente")
                        
                    except Exception as e:
                        debug_log(f"Error procesando imagen {i+1}: {str(e)}")
                        # Agregar mensaje de error al historial
                        st.session_state.graph_state["messages"].append({
                            "role": "assistant",
                            "content": f"Error procesando imagen {uploaded_file.name}: {str(e)}"
                        })
        
        # Recargar la p√°gina para mostrar las respuestas
        st.rerun()
    
    # Informaci√≥n adicional sobre el uso
    st.info("üí° **Tip:** Puedes escribir mensajes, subir im√°genes, o ambos a la vez en el chat de abajo. Las im√°genes se analizan autom√°ticamente.")
    
    # Botones de acci√≥n r√°pida basados en el contexto
    if st.session_state.graph_state:
        render_quick_action_buttons()

def render_quick_action_buttons():
    """Renderiza botones de acci√≥n r√°pida seg√∫n el contexto actual"""
    state = st.session_state.graph_state
    
    # Mostrar bot√≥n para generar p√≥liza si tenemos valuaci√≥n pero no p√≥liza
    if state.get("valuation") and not state.get("policy"):
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üìã Generar P√≥liza", type="primary", use_container_width=True):
                # Agregar mensaje del usuario al historial
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": "Generar p√≥liza"
                })
                
                with st.spinner("Generando p√≥liza completa..."):
                    try:
                        st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                            st.session_state.graph_state, "s√≠, generar p√≥liza"
                        )
                        st.rerun()
                    except Exception as e:
                        st.error(f"Error generando p√≥liza: {str(e)}")
        
        with col2:
            if st.button("üí∞ Ver Cotizaci√≥n", use_container_width=True):
                # Agregar mensaje del usuario al historial
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": "Ver cotizaci√≥n"
                })
                
                with st.spinner("Actualizando cotizaci√≥n..."):
                    try:
                        st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                            st.session_state.graph_state, "mu√©strame el resumen de la cotizaci√≥n"
                        )
                        st.rerun()
                    except Exception as e:
                        st.error(f"Error mostrando cotizaci√≥n: {str(e)}")
    
    # Mostrar bot√≥n para generar audio si tenemos p√≥liza pero no audio
    elif state.get("policy") and not state.get("audio_file"):
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîä Generar Resumen en Audio", use_container_width=True):
                # Agregar mensaje del usuario al historial
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": "Generar resumen en audio"
                })
                
                with st.spinner("Generando resumen en audio..."):
                    try:
                        st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                            st.session_state.graph_state, "s√≠, generar audio"
                        )
                        st.rerun()
                    except Exception as e:
                        st.error(f"Error generando audio: {str(e)}")
        
        with col2:
            if st.button("üìû Informaci√≥n de Contacto", use_container_width=True):
                # Agregar mensaje del usuario al historial
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": "Informaci√≥n de contacto"
                })
                
                with st.spinner("Obteniendo informaci√≥n de contacto..."):
                    try:
                        st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                            st.session_state.graph_state, "dame informaci√≥n de contacto para contratar"
                        )
                        st.rerun()
                    except Exception as e:
                        st.error(f"Error obteniendo contacto: {str(e)}")
    
    # Si ya tenemos todo, mostrar opciones de finalizaci√≥n
    elif state.get("policy") and state.get("audio_file"):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("Ver Coberturas", use_container_width=True):
                # Agregar mensaje del usuario al historial
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": "Ver coberturas"
                })
                try:
                    st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                        st.session_state.graph_state, "expl√≠came las coberturas incluidas"
                    )
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {str(e)}")
        
        with col2:
            if st.button("Informaci√≥n de Costos", use_container_width=True):
                # Agregar mensaje del usuario al historial
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": "Informaci√≥n de costos"
                })
                try:
                    st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                        st.session_state.graph_state, "dame m√°s detalles sobre los costos"
                    )
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {str(e)}")
        
        with col3:
            if st.button("C√≥mo Contratar", use_container_width=True):
                # Agregar mensaje del usuario al historial
                st.session_state.graph_state["messages"].append({
                    "role": "user",
                    "content": "C√≥mo contratar"
                })
                try:
                    st.session_state.graph_state = st.session_state.insurance_graph.process_user_input(
                        st.session_state.graph_state, "quiero contratar el seguro"
                    )
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {str(e)}")


def debug_conversation_flow():
    """Debugging detallado para entender por qu√© falla el flujo - CORREGIDO"""
    if not st.session_state.graph_state:
        return
    
    state = st.session_state.graph_state
    
    st.subheader("üîç An√°lisis del Flujo de Conversaci√≥n")
    
    # 1. Estado actual
    st.write("**1. Estado Actual del Sistema:**")
    st.code(f"""
Current Step: {state.get('current_step', 'Unknown')}
Next Action: {state.get('next_action', 'Unknown')}
Needs Confirmation: {state.get('needs_confirmation', False)}
Ready for Policy: {state.get('ready_for_policy', False)}
    """)
    
    # 2. Datos disponibles
    st.write("**2. Datos Disponibles:**")
    business_info = state.get("business_info", BusinessInfo())
    valuation = state.get("valuation")
    policy = state.get("policy")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**Business Info:**")
        data = business_info.to_dict()
        for key, value in data.items():
            status = "‚úÖ" if value else "‚ùå"
            st.write(f"{status} {key}")
    
    with col2:
        st.write("**Valuaci√≥n:**")
        if valuation:
            st.write("‚úÖ Existe")
            st.write(f"Total: S/ {valuation.total:,.2f}")
        else:
            st.write("‚ùå No existe")
    
    with col3:
        st.write("**P√≥liza:**")
        if policy:
            st.write("‚úÖ Existe")
        else:
            st.write("‚ùå No existe")
    
    # 3. An√°lisis del problema
    st.write("**3. An√°lisis del Problema:**")
    
    # Verificar si debe generar p√≥liza
    should_generate_policy = valuation and not policy
    st.write(f"¬øDeber√≠a generar p√≥liza? {should_generate_policy}")
    
    if should_generate_policy:
        # Verificar qu√© est√° bloqueando la generaci√≥n
        st.write("**¬øQu√© est√° bloqueando la generaci√≥n?**")
        
        if state.get('needs_confirmation'):
            st.warning("üü° Sistema esperando confirmaci√≥n del usuario")
            st.write("El sistema gener√≥ la cotizaci√≥n y est√° esperando que el usuario confirme con 's√≠', 'ok', 'generar', etc.")
        
        if state.get('current_step') == ConversationStep.VALUATION_COMPLETE:
            st.info("üîµ Sistema en paso de valuaci√≥n completa")
            st.write("Deber√≠a estar en modo de espera para confirmaci√≥n")
        
        # Verificar el enrutamiento - CORREGIDO
        st.write("**4. Verificaci√≥n de Enrutamiento:**")
        
        # Manejar user_input de forma segura
        user_input_raw = state.get('user_input', '')
        try:
            if isinstance(user_input_raw, dict):
                # Si es un dict, extraer el texto
                user_input = str(user_input_raw.get('text', '') or user_input_raw.get('message', ''))
            else:
                user_input = str(user_input_raw)
            user_input = user_input.lower()
        except:
            user_input = ''
        
        st.write(f"√öltimo user_input: '{user_input}'")
        st.write(f"Tipo de user_input: {type(state.get('user_input'))}")
        
        confirmation_words = ["s√≠", "si", "ok", "correcto", "generar"]
        has_confirmation = any(word in user_input for word in confirmation_words)
        st.write(f"¬øContiene palabras de confirmaci√≥n? {has_confirmation}")
        
        # Mostrar qu√© ruta tomar√≠a
        if state.get("needs_confirmation") and not has_confirmation:
            st.write("‚Üí Ruta: wait (esperando confirmaci√≥n)")
        elif has_confirmation:
            st.write("‚Üí Ruta: policy_generation")
        else:
            st.write("‚Üí Ruta: sales_assistance")
    
    # 4. √öltimo mensaje del usuario - CORREGIDO
    st.write("**5. Historial de Mensajes Recientes:**")
    messages = state.get("messages", [])
    if messages:
        # Mostrar √∫ltimos 3 mensajes
        for msg in messages[-3:]:
            try:
                role_icon = "üë§" if msg["role"] == "user" else "ü§ñ"
                content = str(msg.get("content", "")).strip()
                # Truncar contenido de forma segura
                if len(content) > 100:
                    content = content[:100] + "..."
                st.write(f"{role_icon} **{msg['role']}:** {content}")
            except Exception as e:
                st.write(f"Error mostrando mensaje: {str(e)}")
    
    return state
# Funci√≥n para testear el enrutamiento manualmente
def test_routing_logic():
    """Testea la l√≥gica de enrutamiento con diferentes inputs"""
    st.subheader("üß™ Test de L√≥gica de Enrutamiento")
    
    if not st.session_state.graph_state:
        st.write("No hay estado del grafo")
        return
    
    state = st.session_state.graph_state
    
    # Input de prueba
    test_input = st.text_input("Probar con este input:", placeholder="s√≠, generar p√≥liza")
    
    if test_input and st.button("Probar Enrutamiento"):
        # Simular el enrutamiento
        st.write("**Resultado del enrutamiento:**")
        
        # Copiar la l√≥gica de _route_from_valuation
        if state.get("needs_confirmation"):
            st.write("1. Sistema necesita confirmaci√≥n: ‚úÖ")
            
            confirmation_words = ["s√≠", "si", "ok", "correcto", "generar"]
            has_confirmation = any(word in test_input.lower() for word in confirmation_words)
            
            if has_confirmation:
                st.success("2. Input contiene confirmaci√≥n: ‚úÖ")
                st.success("‚Üí Deber√≠a ir a: policy_generation")
                
                # Probar generar p√≥liza manualmente
                if st.button("Ejecutar Generaci√≥n de P√≥liza"):
                    try:
                        # Actualizar estado
                        state["user_input"] = test_input
                        
                        # Llamar al nodo directamente
                        new_state = st.session_state.insurance_graph.nodes.policy_generation_node(state)
                        
                        if new_state.get("policy"):
                            st.success("P√≥liza generada exitosamente!")
                            st.session_state.graph_state = new_state
                            st.rerun()
                        else:
                            st.error("No se pudo generar la p√≥liza")
                            
                    except Exception as e:
                        st.error(f"Error: {str(e)}")
                        traceback.print_exc()
            else:
                st.warning("2. Input NO contiene confirmaci√≥n: ‚ùå")
                st.warning("‚Üí Permanecer√≠a en: wait")
        else:
            st.write("1. Sistema NO necesita confirmaci√≥n: ‚ùå")
            st.write("‚Üí Ir√≠a a: sales_assistance")

# Funci√≥n para forzar el paso correcto
def force_correct_step():
    """Fuerza el sistema al paso correcto basado en los datos disponibles"""
    if not st.session_state.graph_state:
        return
    
    state = st.session_state.graph_state
    
    st.subheader("üîß Corregir Estado del Sistema")
    
    if st.button("Forzar Estado Correcto"):
        try:
            # Determinar el estado correcto basado en los datos
            if state.get("policy"):
                state["current_step"] = ConversationStep.POLICY_GENERATED
                state["next_action"] = "offer_audio"
                state["needs_confirmation"] = False
                st.success("Estado corregido a: POLICY_GENERATED")
                
            elif state.get("valuation"):
                state["current_step"] = ConversationStep.VALUATION_COMPLETE
                state["next_action"] = "await_confirmation"
                state["needs_confirmation"] = True
                st.success("Estado corregido a: VALUATION_COMPLETE")
                
            else:
                state["current_step"] = ConversationStep.GATHERING_INFO
                state["next_action"] = "gather_info"
                state["needs_confirmation"] = False
                st.success("Estado corregido a: GATHERING_INFO")
            
            st.rerun()
            
        except Exception as e:
            st.error(f"Error: {str(e)}")
            traceback.print_exc()
def main():
    """Funci√≥n principal de la aplicaci√≥n"""
    
    # Header principal
    st.markdown("""
    <div class="main-header">
        <h1>ü§ñ Agente de Seguros IA - Pac√≠fico</h1>
        <p>Tu asistente inteligente para seguros comerciales personalizados</p>
        <small>üí° Ahora puedes subir im√°genes directamente en el chat - detecta autom√°ticamente certificados y fotos del local</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Inicializar estado
    initialize_session_state()
    
    # Sidebar para configuraci√≥n
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # API Key
        api_key = st.secrets["api_key"] #st.text_input(
           # "üîë API Key de OpenAI:",
          #  type="password",
         #   value=st.session_state.get("api_key", ""),
         #   help="Ingresa tu API Key de OpenAI"
        #)
        
        if api_key != st.session_state.api_key:
            st.session_state.api_key = api_key
            # Resetear el grafo si cambia la API key
            st.session_state.insurance_graph = None
            st.session_state.graph_state = None
            st.session_state.conversation_initialized = False
        
        if not api_key:
            st.warning("‚ö†Ô∏è Ingresa tu API Key para comenzar")
            st.info("üí° Este agente usa GPT-3.5-turbo y GPT-4o-mini (APIs econ√≥micas)")
            return
        
        # Configurar grafo
        if setup_insurance_graph(api_key):
            st.success("‚úÖ Agente configurado")
        else:
            return
        
        st.divider()
        
        # Panel de progreso
        render_progress_panel()
        
        st.divider()
        
        # Panel de informaci√≥n del negocio
        render_business_info_panel()
        
        st.divider()
        
        # Panel de descargas
        render_downloads_panel()
        
        st.divider()
        
        # Galer√≠a de im√°genes
        render_image_gallery()
        
        st.divider()
        
        # Debug setup
        debug_setup()
        
        st.divider()
        if st.session_state.get("debug_mode"):
            st.divider()
            debug_conversation_flow()
            st.divider()
            test_routing_logic()
            st.divider()
            force_correct_step()
        # Bot√≥n para reiniciar
        if st.button("üîÑ Nueva Consulta", use_container_width=True):
            # Limpiar estado pero mantener API key
            api_key_backup = st.session_state.api_key
            st.session_state.clear()
            st.session_state.api_key = api_key_backup
            st.rerun()
    
    # Layout principal - solo conversaci√≥n ahora
    # Conversaci√≥n principal (ocupa todo el ancho)
    render_conversation()
    
    # Informaci√≥n del estado actual (colapsado por defecto)
    if st.session_state.graph_state:
        with st.expander("üîç Estado del Sistema", expanded=False):
            summary = st.session_state.insurance_graph.get_conversation_summary(
                st.session_state.graph_state
            )
            st.json(summary)

def render_memory_panel():
    """Renderiza el panel de memoria de contexto"""
    if not st.session_state.get("insurance_agent"):
        return
    
    st.subheader("üß† Memoria de Contexto")
    
    try:
        memory_summary = st.session_state.insurance_agent.get_memory_summary()
        
        # Estilo conversacional
        if memory_summary["conversation_style"]:
            style_color = "üéØ" if memory_summary["conversation_style"] == "formal" else "üòä"
            st.write(f"{style_color} **Estilo:** {memory_summary['conversation_style'].title()}")
        
        # Preferencias del usuario
        if memory_summary["user_preferences"]:
            st.write("‚≠ê **Preferencias detectadas:**")
            for key, value in memory_summary["user_preferences"].items():
                st.write(f"  ‚Ä¢ {key}: {value}")
        
        # Contexto del negocio
        if memory_summary["business_context"]:
            st.write("üè¢ **Contexto del negocio:**")
            for key, value in memory_summary["business_context"].items():
                st.write(f"  ‚Ä¢ {key}: {value}")
        
        # Estad√≠sticas de interacci√≥n
        st.write(f"üí¨ **Interacciones:** {memory_summary['interaction_history_count']}")
        st.write(f"‚ö†Ô∏è **Preocupaciones:** {memory_summary['mentioned_concerns_count']}")
        
        # Mostrar memoria completa en expander para debugging
        with st.expander("üîç Memoria completa (Debug)", expanded=False):
            full_memory = st.session_state.insurance_agent.context_memory
            st.json(full_memory)
    
    except Exception as e:
        st.error(f"Error mostrando memoria: {str(e)}")

def render_enhanced_conversation_llm():
    """Renderiza la conversaci√≥n con el agente LLM - CORREGIDO"""
    st.subheader("üí¨ Conversaci√≥n con tu Agente de Seguros IA")
    
    if not st.session_state.graph_state:
        st.warning("Configura tu API Key para comenzar")
        return
    
    # Mostrar indicadores de memoria activa
    if st.session_state.get("insurance_agent"):
        try:
            memory_summary = st.session_state.insurance_agent.get_memory_summary()
            
            if any(memory_summary.values()):
                cols = st.columns([1, 1, 1, 1])
                
                with cols[0]:
                    if memory_summary["conversation_style"]:
                        style_icon = "üéØ" if memory_summary["conversation_style"] == "formal" else "üòä"
                        st.caption(f"{style_icon} {memory_summary['conversation_style'].title()}")
                
                with cols[1]:
                    if memory_summary["user_preferences"]:
                        st.caption(f"‚≠ê {len(memory_summary['user_preferences'])} preferencias")
                
                with cols[2]:
                    if memory_summary["interaction_history_count"] > 0:
                        st.caption(f"üí¨ {memory_summary['interaction_history_count']} interacciones")
                
                with cols[3]:
                    if memory_summary["mentioned_concerns_count"] > 0:
                        st.caption(f"‚ö†Ô∏è {memory_summary['mentioned_concerns_count']} preocupaciones")
        except Exception as e:
            debug_log(f"Error mostrando memoria: {str(e)}")
    
    # Mostrar mensajes de la conversaci√≥n
    messages = st.session_state.graph_state.get("messages", [])
    
    for message in messages:
        if message["role"] == "user":
            st.chat_message("user").write(message["content"])
        else:
            st.chat_message("assistant").write(message["content"])
    check_and_update_audio_state()
    # Chat input con soporte para archivos
    try:
        prompt = st.chat_input(
            "Conversa naturalmente - el IA recuerda el contexto...",
            accept_file=True,
            file_type=["jpg", "jpeg", "png"]
        )
    except:
        # Fallback para versiones de Streamlit sin soporte de archivos
        col1, col2 = st.columns([4, 1])
        with col1:
            text_input = st.text_input("Escribe tu mensaje:", key="text_input")
        with col2:
            uploaded_files = st.file_uploader("Subir imagen", type=["jpg", "jpeg", "png"], 
                                            accept_multiple_files=True, key="file_upload")
        
        prompt = None
        if text_input or uploaded_files:
            prompt = {
                'text': text_input if text_input else "",
                'files': uploaded_files if uploaded_files else []
            }
    
    if prompt:
        # Manejar diferentes tipos de input
        if isinstance(prompt, str):
            user_message = prompt
            uploaded_files = []
        elif hasattr(prompt, 'text') and hasattr(prompt, 'files'):
            user_message = prompt.text if prompt.text else ""
            uploaded_files = prompt.files if prompt.files else []
        elif isinstance(prompt, dict):
            user_message = prompt.get('text', '')
            uploaded_files = prompt.get('files', [])
        else:
            user_message = str(prompt)
            uploaded_files = []
        
        # Procesar im√°genes primero (si las hay)
        if uploaded_files:
            if not isinstance(uploaded_files, list):
                uploaded_files = [uploaded_files]
                
            for uploaded_file in uploaded_files:
                debug_log(f"Procesando imagen: {uploaded_file.name}")
                
                with st.spinner(f"Analizando {uploaded_file.name}..."):
                    try:
                        # CORREGIDO: Procesar la imagen directamente con el agente LLM
                        new_state, response_msg = process_uploaded_image_llm(
                            uploaded_file, 
                            st.session_state.graph_state,
                            st.session_state.insurance_agent,
                            st.session_state.api_key
                        )
                        
                        # Actualizar el estado
                        st.session_state.graph_state = new_state
                        debug_log(f"Imagen {uploaded_file.name} procesada exitosamente")
                        
                    except Exception as e:
                        debug_log(f"Error procesando imagen: {str(e)}")
                        st.error(f"Error procesando imagen: {str(e)}")
        
        # Procesar mensaje de texto (si lo hay)
        if user_message and user_message.strip():
            with st.spinner("Procesando mensaje..."):
                try:
                    # Usar el agente LLM para procesar la conversaci√≥n
                    st.session_state.graph_state = st.session_state.insurance_agent.process_conversation(
                        st.session_state.graph_state, 
                        user_message
                    )
                    debug_log("Mensaje de texto procesado exitosamente")
                except Exception as e:
                    debug_log(f"Error en la conversaci√≥n: {str(e)}")
                    st.error(f"Error en la conversaci√≥n: {str(e)}")
        
        # Si se proces√≥ algo, recargar la p√°gina
        if (uploaded_files and len(uploaded_files) > 0) or (user_message and user_message.strip()):
            st.rerun()
    
    # Informaci√≥n adicional
    st.info("üß† **IA con memoria** - Recuerda tus preferencias y el contexto de la conversaci√≥n")
# Cambios necesarios en main.py para usar el agente controlado por LLM
def debug_log(message, data=None):
    """Funci√≥n para logging de debug mejorada"""
    print(f"[DEBUG] {message}")
    if data:
        print(f"[DEBUG DATA] {data}")
    
    # Tambi√©n mostrar en Streamlit si est√° en debug mode
    if st.session_state.get("debug_mode", False):
        st.write(f"üîç DEBUG: {message}")
        if data:
            st.json(data)
def setup_insurance_agent(api_key: str):
    """Configura el agente de seguros controlado por LLM - CORREGIDO"""
    try:
        if not st.session_state.get("insurance_agent"):
            st.session_state.insurance_agent = LLMControlledInsuranceAgent(api_key)
            st.session_state.graph_state = create_initial_state()
            
            # Mensaje de bienvenida inicial
            welcome_message = {
                "role": "assistant",
                "content": """¬°Hola! Soy tu agente de seguros comerciales de Seguros Pac√≠fico.

Estoy aqu√≠ para ayudarte a crear una p√≥liza personalizada para tu negocio de manera completamente conversacional. 

Puedes:
üìÑ Subir tu certificado de funcionamiento
üì∏ Enviar fotos de tu local
üí¨ Contarme sobre tu negocio directamente

Solo comparte la informaci√≥n que tengas disponible y yo me encargar√© de guiarte naturalmente en el proceso. ¬øC√≥mo te gustar√≠a empezar?"""
            }
            
            st.session_state.graph_state["messages"] = [welcome_message]
            
        return True
    except Exception as e:
        st.error(f"Error configurando el agente: {str(e)}")
        import traceback
        traceback.print_exc()  # Para ver el error completo
        return False


def create_initial_state() -> dict:  # Cambiado de GraphState a dict
    """Crea el estado inicial simplificado"""
    return {
        "messages": [],
        "business_info": BusinessInfo(),
        "valuation": None,
        "certificate_text": None,
        "certificate_images": [],
        "local_photos": [],
        "policy": None,
        "audio_file": None,
        "audio_summary": None,
        "session_id": str(uuid.uuid4()),
        "timestamp": datetime.now().isoformat()
    }

def process_uploaded_image_llm(uploaded_file, graph_state, insurance_agent, api_key):
    """Procesa imagen subida para el agente LLM - CORREGIDO"""
    try:
        debug_log(f"Procesando imagen: {uploaded_file.name}")
        
        # Convertir a PIL Image
        pil_image = Image.open(uploaded_file)
        debug_log(f"PIL Image cargada: {pil_image.size}")
        
        # Clasificar tipo de imagen
        image_type = classify_image_type(pil_image, api_key)
        debug_log(f"Tipo de imagen detectado: {image_type}")
        
        if image_type == "certificate":
            # Procesar certificado
            debug_log("Procesando como certificado...")
            graph_state = insurance_agent.process_certificate_image(graph_state, pil_image)
            
            # IMPORTANTE: Hacer que el LLM procese la imagen autom√°ticamente
            graph_state = insurance_agent.process_conversation(
                graph_state, 
                f"He subido una imagen de mi certificado de funcionamiento ({uploaded_file.name}). Por favor anal√≠zalo para extraer la informaci√≥n de mi negocio."
            )
            
            # La respuesta ya est√° en los mensajes del estado
            return graph_state, "Procesando certificado..."
            
        else:  # local_photo
            # Procesar foto del local
            debug_log("Procesando como foto del local...")
            graph_state = insurance_agent.process_local_photos(graph_state, [pil_image])
            current_photos = len(graph_state.get("local_photos", []))
            
            # IMPORTANTE: Hacer que el LLM procese la foto autom√°ticamente
            graph_state = insurance_agent.process_conversation(
                graph_state, 
                f"He subido una foto de mi local comercial ({uploaded_file.name}). Ahora tienes {current_photos} imagen(es) para la valuaci√≥n."
            )
            
            # La respuesta ya est√° en los mensajes del estado
            return graph_state, "Procesando foto del local..."
        
    except Exception as e:
        error_msg = f"Error procesando imagen: {str(e)}"
        debug_log(error_msg)
        import traceback
        traceback.print_exc()
        return graph_state, error_msg

def main_enhanced():
    """Funci√≥n principal mejorada con memoria de contexto"""
    
    # Header principal
    st.markdown("""
    <div class="main-header">
        <h1>ü§ñ Agente de Seguros IA - Pac√≠fico (Con Memoria)</h1>
        <p>Tu asistente conversacional inteligente que recuerda el contexto</p>
        <small>üß† Memoria de contexto activa - Adapta su comunicaci√≥n a tus preferencias</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Inicializar estado
    initialize_session_state()
    
    # Sidebar para configuraci√≥n
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # API Key
        api_key = st.secrets["api_key"] # st.text_input(
           # "üîë API Key de OpenAI:",
         #   type="password",
         #   value=st.session_state.get("api_key", ""),
        #    help="Necesita GPT-4 Turbo para mejores resultados"
        #)
        
        if api_key != st.session_state.api_key:
            st.session_state.api_key = api_key
            st.session_state.insurance_agent = None
            st.session_state.graph_state = None
        
        if not api_key:
            st.warning("‚ö†Ô∏è Ingresa tu API Key para comenzar")
            st.info("üß† Este agente usa GPT-4 Turbo con memoria de contexto")
            return
        
        # Configurar agente
        if setup_insurance_agent(api_key):
            st.success("‚úÖ Agente IA configurado")
        else:
            return
        
        st.divider()
        
        # Panel de memoria de contexto
        render_memory_panel()
        
        st.divider()
        
        # Panel de progreso simplificado
        render_progress_panel()
        
        st.divider()
        
        # Panel de informaci√≥n del negocio
        render_business_info_panel()
        
        st.divider()
        
        # Panel de descargas
        render_downloads_panel()
        
        st.divider()
        
        # Bot√≥n para reiniciar (con advertencia sobre p√©rdida de memoria)
        if st.button("üîÑ Nueva Consulta", use_container_width=True):
            if st.session_state.get("insurance_agent") and st.session_state.insurance_agent.context_memory["interaction_history"]:
                st.warning("‚ö†Ô∏è Esto borrar√° la memoria de contexto. ¬øContinuar?")
                if st.button("‚úÖ S√≠, reiniciar", use_container_width=True):
                    api_key_backup = st.session_state.api_key
                    st.session_state.clear()
                    st.session_state.api_key = api_key_backup
                    st.rerun()
            else:
                api_key_backup = st.session_state.api_key
                st.session_state.clear()
                st.session_state.api_key = api_key_backup
                st.rerun()
    
    # Conversaci√≥n principal con memoria
    render_enhanced_conversation_llm()
    
    # Estado del sistema (colapsado)
    if st.session_state.graph_state:
        with st.expander("üîç Estado del Sistema", expanded=False):
            summary = {
                "business_info": st.session_state.graph_state.get("business_info", {}).to_dict() if st.session_state.graph_state.get("business_info") else {},
                "has_valuation": bool(st.session_state.graph_state.get("valuation")),
                "has_policy": bool(st.session_state.graph_state.get("policy")),
                "has_audio": bool(st.session_state.graph_state.get("audio_file")),
                "photos_count": len(st.session_state.graph_state.get("local_photos", [])),
                "certificate_count": len(st.session_state.graph_state.get("certificate_images", []))
            }
            st.json(summary)
            
            # Mostrar memoria del agente
            if st.session_state.get("insurance_agent"):
                st.subheader("Memoria del Agente")
                memory_data = st.session_state.insurance_agent.context_memory
                st.json(memory_data)

# Funci√≥n adicional para testing de memoria
def test_memory_functionality():
    """Funci√≥n de testing para verificar que la memoria funciona correctamente"""
    if st.session_state.get("insurance_agent"):
        st.subheader("üß™ Test de Memoria")
        
        if st.button("Simular interacci√≥n de test"):
            test_input = "Hola, tengo una panader√≠a y me preocupa mucho el tema de incendios"
            
            # Procesar input de test
            st.session_state.graph_state = st.session_state.insurance_agent.process_conversation(
                st.session_state.graph_state, 
                test_input
            )
            
            # Mostrar memoria actualizada
            memory = st.session_state.insurance_agent.get_memory_summary()
            st.json(memory)
            
            st.success("Test completado - revisa la memoria actualizada")

if __name__ == "__main__":
    main_enhanced()